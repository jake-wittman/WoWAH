---
title: "Untitled"
author: "Jake Wittman"
date: "8/4/2021"
output: html_document
---
```{r}
Sys.time()

# R imports
.libPaths("F:/Documents/WoWAH/renv/library/R-4.0/x86_64-w64-mingw32")
library(httr)
library(jsonlite)
library(tidyverse)
library(glue)
library(googledrive)
library(reticulate)
library(lubridate)
library(emayili)
use_condaenv("F:\\Documents\\WoWAH\\renv\\python\\condaenvs\\renv-python\\python.exe")

`%!in%` <- Negate(`%in%`)

source('data/keys.R')

```

```{python}
# Set up python functions
import requests
from datetime import datetime
import pandas as pd

# Create a new access token
def create_access_token(client_id, client_secret, region = "us"):
   data = { 'grant_type': 'client_credentials' }
   response = requests.post('https://%s.battle.net/oauth/token' % region,
                            data = data,
                            auth = (client_id, client_secret))
   return response.json()

# Get Malf and connected realms data
def get_malfurion(search):
   search = search
   response = requests.get(search)
   return response.json()["auctions"]
```

### Set up API call

```{python}
response = create_access_token(r['client_id'], r['client_secret'])
token = response['access_token']
```

```{r}
# Set up search query with Malfurion realm ID
id <- 1175
token <- py$token
search <- glue("https://us.api.blizzard.com/data/wow/connected-realm/{id}/auctions?namespace=dynamic-us&locale=en_US&access_token={token}")
```

### Get the data

```{python}
auction_data = get_malfurion(r['search'])
auction_data = pd.DataFrame(auction_data)
# Expand the item column
auction_data = auction_data.rename(columns={"id": "auction_id",})
auction_data = pd.concat([auction_data.drop(['item'], axis=1), auction_data['item'].apply(pd.Series)], axis=1)

# Drop 'bonus_list' and 'modifiers' 
#   These are subgroups of an equipable item with the bonus stats (intellect agility, strength, etc)
auction_data['collection_year'] = datetime.now().strftime('%Y')
auction_data['collection_month'] = datetime.now().strftime('%m')
auction_data['collection_day'] = datetime.now().strftime('%d')
auction_data['collection_hour'] = datetime.now().strftime('%H')
filename = datetime.now().strftime('F:/Documents/WoWAH/data/Malfurion_NA-%Y-%m-%d-%H-%M.csv')
tablename = datetime.now().strftime('Malfurion_NA-%Y-%m-%d-%H-%M')
auction_data.to_csv(filename, index = False)
```

### Clean the data
 
```{r}
# Read the data into R to clean it a bit more (since I'm less good at cleaning)
# in python
auction_df <- read_csv(py$filename)

# Unit prices are for stackable items 
auction_df <- auction_df %>% 
   mutate(unit_price = replace_na(unit_price, 0),
          buyout = replace_na(buyout, 0),
          cost = unit_price + buyout,
          cost_g = cost / 10000)

write_csv(auction_df, py$filename)

# Add to database
library(RSQLite)
library(dbplyr)

con <- dbConnect(RSQLite::SQLite(), "data/WoWAH_database.sqlite")
dbWriteTable(con, py$tablename, auction_df)
file.remove(py$filename) # delete the csv file once it is in the database.
```

# Update database

```{r}
# Check for any items in the newly scraped AH data that isn't in
# the current database
item_db <- tbl(con, "item_name")
auction_df <- tbl(con, py$tablename)
not_in_db_df <- anti_join(auction_df, item_db, by = "id") %>% 
   collect()
id <- 1175
token <- py$token
# Format item info to request from API
item_ids <- unique(not_in_db_df$id)

# Helper function to chunk id vector
createChunks <- function(x, elements.per.chunk){
   # plain R version
   split(x, rep(seq_along(x), each = elements.per.chunk)[seq_along(x)])

}

item_chunks <- createChunks(item_ids, 50)
search_chunks <- map(item_chunks, function(.x) {
   id_char <- paste(.x, collapse = "||")
   glue("https://us.api.blizzard.com/data/wow/search/item?namespace=static-us&locale=en_US&orderby=id&&_pageSize=1000&id={id_char}&_&access_token={token}")
})
# Need this to be a Python list so I remove names (a named list becomes a python dict)
search_chunks <- unname(search_chunks)
```


```{python}
import pandas
item_names = []

for search_url in r['search_chunks']:
   response = requests.get(search_url).json()
   response_df = pandas.io.json.json_normalize(response, record_path = ['results'])
   item_names.append(response_df)


item_df = pd.concat(item_names, ignore_index = True, axis = 0, sort = True)

```

```{r}
# Get Item classes index an
new_item_df <- py$item_df %>% 
   select(data.id, data.is_equippable, data.is_stackable, data.level, data.max_count,
          data.media.id,  data.name.en_US,
          data.purchase_price, data.required_level, data.sell_price) %>% 
   rename_all(~stringr::str_replace(., "^data.", "")) %>% 
   rename_at(.vars = vars(ends_with(".en_US")),
             ~ sub('[.]en_US$', '', .))

dbAppendTable(con, name = "item_name", value = new_item_df)
```

# Remove excess data

Had this turned on, but I'm gonna turn it off again for a while.

```{r, eval = FALSE}
# I don't need to keep all the data, let's keep a month's worth
table_list <- data.frame(table_list = dbListTables(con))
table_list <- filter(table_list, table_list %!in% c("item_name", "item_db"))
table_list$date_times <-
   str_extract(table_list$table_list,
               "[0-9]{4}-[0-9]{2}-[0-9]{2}-[0-9]{2}-[0-9]{2}")
table_list$date_times <- ymd_hm(table_list$date_times)
# Just in case the tables aren't in order for date time
table_list$index <- 1:nrow(table_list)
table_list <- arrange(table_list, desc(date_times))
keep_tables <- slice(table_list, 1:672)
remove_tables <- table_list[table_list$index %!in% keep_tables$index, ]
remove_tables <- remove_tables$table_list

map(remove_tables, ~dbRemoveTable(con, .x))
dbDisconnect(con)

```

# Email alerts for particular items

Turning this off for now. Apparently I violated gmail terms of service *crying laughing emoji*. I'll figure out something else later.

```{r, eval = FALSE}
watched_items <- c('Elethium Ore', 'Widowbloom')
watched_item_df <- auction_df %>% 
   left_join(item_db, by = 'id', copy = TRUE) %>% 
   filter(name %in% watched_items) %>% 
   select(name, cost_g, quantity) %>% 
   group_by(name, cost_g) %>% 
   summarise(quantity = sum(quantity, na.rm = TRUE)) %>% 
   collect()

email_items <- watched_item_df %>% 
   group_by(name) %>% 
   summarise(min_cost = min(cost_g)) %>%
   left_join(., watched_item_df, by = c('name', 'min_cost' = 'cost_g')) %>% 
   mutate(buy = case_when(name == 'Elethium Ore' & min_cost < 60 ~ 1,
                          name == 'Widowbloom' & min_cost < 16 ~ 1,
                          TRUE ~ 0)) %>% 
   filter(buy == 1)
items_to_buy <- paste0(email_items$name, ": ", email_items$quantity, collapse = ", ")
names(items_to_buy) <- 'items_to_buy'
# Set up text to send the giver their assigned gift recipient
if (nrow(email_items) > 0) {
body <- "Dear Jake,

<p>Consider purchasing the following items:
<br> {items_to_buy}

"

# Set up email
email <- envelope()
email <- email %>% 
   from("wittman.secret.santa@gmail.com") %>% 
   to('wittja01@gmail.com')

email <- email %>% 
   subject(paste0('WoW AH ', Sys.time()))

email <- email %>% 
   html(glue_data(items_to_buy, body))


smtp <- server(host = "smtp.gmail.com",
               port = 587,
               username = "wittman.secret.santa@gmail.com",
               password = "znbsqeduqaclxecj")
smtp(email, verbose = TRUE)
}
```

